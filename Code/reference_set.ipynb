{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "    1. Welke dimensies moeten worden opgevraagd en welke berekend?\n",
    "    2. Gegeven de opgevraagde dimensies, bereken de overige relevante.\n",
    "    3. Voor een comparable featuere i.e. toilet: doe een voorspelling met en een voorspelling zonder het toilet.\n",
    "    4. Kijk naar de resulterende voorspellingen, het verschil is de verwachte toegevoegde waarde\n",
    "    5. Gebruik fci om de confidence interval te geven!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:45.781004Z",
     "start_time": "2018-12-04T19:27:44.458455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: forestci in /home/stefan/anaconda3/lib/python3.6/site-packages (0.3)\r\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/stefan/anaconda3/lib/python3.6/site-packages (from forestci) (1.14.2)\r\n",
      "Requirement already satisfied: nose>=1.1.2 in /home/stefan/anaconda3/lib/python3.6/site-packages (from forestci) (1.3.7)\r\n",
      "Requirement already satisfied: scikit-learn>=0.17 in /home/stefan/anaconda3/lib/python3.6/site-packages (from forestci) (0.19.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install forestci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.475911Z",
     "start_time": "2018-12-04T19:27:45.783135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "Failed to import duecredit due to No module named 'duecredit'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numbers\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tkinter import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from preprocessing import *\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from preprocessing import *\n",
    "import forestci as fci\n",
    "\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For earlier analysis, we took the log of the endprice, this time however, we are interested in the effect of certain variables on  the real endprice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.600571Z",
     "start_time": "2018-12-04T19:27:46.477264Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pickle.load(open('houses.p','rb'))\n",
    "train_cats(df)\n",
    "# df['endprice'] = np.exp(df['endprice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a few comparable features, we should add some more in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.605085Z",
     "start_time": "2018-12-04T19:27:46.602002Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_features = ['bathroom.badkamer','feature.zwembad','bathroom.aparte toilet','balcony.balkon','feature.sauna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.626166Z",
     "start_time": "2018-12-04T19:27:46.607495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathroom.badkamer         0\n",
       "feature.zwembad           0\n",
       "bathroom.aparte toilet    1\n",
       "balcony.balkon            0\n",
       "feature.sauna             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[compare_features].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.719091Z",
     "start_time": "2018-12-04T19:27:46.628099Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=compare_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.725030Z",
     "start_time": "2018-12-04T19:27:46.720572Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = {\"livingspace\" : 0.377048,\n",
    "           \"Gemiddelde woningwaarde:x 1 000 euro\" : 0.148191,\n",
    "           \"housetype\" : 0.116821,\n",
    "           \"V1.x\":0.031711,\n",
    "           \"lotsurface\":0.045889,\n",
    "           \"yearofconstruction\":0.024880,\n",
    "           \"longitude\":0.016243,\n",
    "           'latitude':0.013181,\n",
    "           'housesubtype':0.018080,\n",
    "           'rooms' : 0.016288\n",
    "        }\n",
    "rcf = list(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:36:40.811989Z",
     "start_time": "2018-12-04T19:36:40.809057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['livingspace', 'Gemiddelde woningwaarde:x 1 000 euro', 'housetype', 'V1.x', 'lotsurface', 'yearofconstruction', 'longitude', 'latitude', 'housesubtype', 'rooms']\n"
     ]
    }
   ],
   "source": [
    "print(rcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.755479Z",
     "start_time": "2018-12-04T19:27:46.726799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "livingspace                              4575\n",
       "Gemiddelde woningwaarde:x 1 000 euro     1866\n",
       "housetype                                   0\n",
       "V1.x                                        0\n",
       "lotsurface                              24943\n",
       "yearofconstruction                       4288\n",
       "longitude                                   0\n",
       "latitude                                    0\n",
       "housesubtype                                0\n",
       "rooms                                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[rcf].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.767505Z",
     "start_time": "2018-12-04T19:27:46.757245Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = {\"livingspace\" : 0.377048,\n",
    "           \"Gemiddelde woningwaarde:x 1 000 euro\" : 0.148191,\n",
    "           \"housetype\" : 0.116821,\n",
    "           \"V1.x\":0.031711,\n",
    "           \"lotsurface\":0.045889,\n",
    "           \"yearofconstruction\":0.024880,\n",
    "           \"longitude\":0.016243,\n",
    "           'latitude':0.013181,\n",
    "           'housesubtype':0.018080,\n",
    "           'rooms' : 0.016288\n",
    "        }\n",
    "\n",
    "#Normalize weights \n",
    "sum_vals = sum(weights.values())\n",
    "for key in weights.keys():\n",
    "    weights[key] = weights[key] / sum_vals\n",
    "    \n",
    "rcf = list(weights.keys())\n",
    "#ccf = [\"housesubtype\",\"housetype\"]\n",
    "#ccf = ['feature.zwembad','feature.sauna', 'feature.glasvezelkabel']\n",
    "#       'feature.stoomcabine', 'feature.stoomcabine','feature.jacuzzi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.797450Z",
     "start_time": "2018-12-04T19:27:46.768889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appartement        19794\n",
       "eengezinswoning     4409\n",
       "herenhuis            310\n",
       "villa                168\n",
       "bungalow             146\n",
       "woonboerderij         65\n",
       "landhuis              28\n",
       "woonboot              14\n",
       "grachtenpand           8\n",
       "stacaravan             1\n",
       "landgoed               0\n",
       "Name: housetype, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['lotsurface'].isnull()].housetype.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column with the most missing values is \"lotsurface\". Looking at how these missing values are centered, we see that most of these missing values happen for appartments (which is to be expected). As it turns out, all appartments have lotsurface Nan. For the purpose of the regression we put this value to 0 for all appartments.\n",
    "\n",
    "For all the other values, in order to empower regression, we could either drop the row or set the value to the average of the housetype. Since there appears to be plenty of data without Nans and since we want to use mostly accurate data, we decide to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:27:46.913019Z",
     "start_time": "2018-12-04T19:27:46.798939Z"
    }
   },
   "outputs": [],
   "source": [
    "df['lotsurface'] = np.where(df['housetype'] == 'appartement', 0, df['lotsurface'])\n",
    "df = df.dropna(subset=rcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:32:12.445559Z",
     "start_time": "2018-12-04T19:32:12.426984Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(df[rcf + compare_features + ['endprice']] ,open('../Data/reduced_df.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still left with 66239 rows, which should be plenty of data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:53:35.231583Z",
     "start_time": "2018-12-04T18:53:35.151125Z"
    }
   },
   "outputs": [],
   "source": [
    "# weights --> dictionary of feature name to importance\n",
    "# data --> pandas datafram of houses with all relevant features\n",
    "# rcf --> list of all relevant features \n",
    "# puf --> list of all potentially upgradable features -should be a subset of relevant features \n",
    "# thres --> maximum distance a house can have from the target house if it is to be put in a reference set \n",
    "# target_house\n",
    "\n",
    "def normalize_column(x):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return x_scaled, min_max_scaler\n",
    "\n",
    "def weightedL2(a,b,w):\n",
    "    dif = []\n",
    "    for i, val in enumerate(a[0]):\n",
    "        if(type(val)==type(\"a\")):\n",
    "            if val == b[i]:\n",
    "                dif.append(0)\n",
    "            else:\n",
    "                dif.append(1)\n",
    "        else:\n",
    "            dif.append(abs(a[0][i]-b[i]))\n",
    "    q = dif\n",
    "    return np.sqrt((w*q*q).sum())\n",
    "\n",
    "# rcf --> relevent comparable features rcfv--> relevant comparable feature values puf --> potential upgradable features\n",
    "def get_reference_indices(weights, data, thres, target_values):\n",
    "    reference_indices = []\n",
    "    for i, house in enumerate(data):\n",
    "        if weightedL2(target_values, house,weights) <  thres:\n",
    "            reference_indices.append(i)\n",
    "    return reference_indices\n",
    "\n",
    "def get_reference_sets(weights, rcf, ccf, data, target_house, thres=1):\n",
    "    df_ans = data.copy()\n",
    "    df = data[rcf+ccf] # We only look only at the columns that were determined to be relevant for comparison\n",
    "    t_house = target_house[rcf+ccf]\n",
    "#     for col in ccf:\n",
    "#         val = t_house[col].iloc[0]\n",
    "#         df = df[df[col]==val]\n",
    "    for col in df[rcf].columns:\n",
    "        if (df[col].dtype in [bool,float,int,np.int64]):\n",
    "            a, b = normalize_column(df[[col]].values.astype(float))\n",
    "            df[col] = a\n",
    "            t_house[col] = b.transform(t_house[[col]].values.astype(float))\n",
    "    target_values = t_house[rcf].values\n",
    "    data_array = df[rcf].values\n",
    "#     return target_values\n",
    "    weights_arr = np.array(list(weights.copy().values()))\n",
    "    reference_index = get_reference_indices(weights_arr, data_array, thres, target_values)\n",
    "    return df_ans.iloc[reference_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:53:35.245343Z",
     "start_time": "2018-12-04T18:53:35.233383Z"
    }
   },
   "outputs": [],
   "source": [
    "# thresh is a measure of how close a house has to be to the target house in order for it to be similar\n",
    "thresh = 1\n",
    "t_house = pd.DataFrame(df.iloc[2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:53:37.764663Z",
     "start_time": "2018-12-04T18:53:35.249848Z"
    }
   },
   "outputs": [],
   "source": [
    "ref_sets = get_reference_sets(weights=weights, rcf = rcf, ccf = compare_features, data= df, target_house= t_house,thres=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:53:37.783084Z",
     "start_time": "2018-12-04T18:53:37.766328Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_importance (reference_sets, rcf, compare_features):\n",
    "    #This function will fit a simple regression in the data and return the feature importances for each upgradable feature\n",
    "    # It will also return the test R2 score\n",
    "    #drop NaN values #note we took the easy approach and dropped everything \n",
    "    df_result = reference_sets[rcf + compare_features + ['endprice']].dropna()\n",
    "    #scaling the data\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit (df_result[rcf + compare_features])\n",
    "    #creating X,y and spliting the dataset into train and test set\n",
    "#     X = scaler.transform(df_result[rcf + compare_features])\n",
    "    X = df_result[rcf + compare_features]\n",
    "    y = df_result.endprice\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    #fitting the regression\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    score = reg.score(X_test, y_test)\n",
    "    feature_imp = pd.Series(data=reg.coef_, index = rcf+compare_features)\n",
    "    return (score,feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we're gonna try to do this based on the randomforrestregression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string data to categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:53:37.950155Z",
     "start_time": "2018-12-04T18:53:37.785485Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = ref_sets[rcf + compare_features + ['endprice']].dropna()\n",
    "train_cats(data)\n",
    "X, y, _ = proc_df(data, 'endprice')\n",
    "\n",
    "n_trn = len(X) // 2\n",
    "n_valid = n_trn + (len(X) // 4)\n",
    "X_train, X_valid, X_test = split_vals_test(X, n_trn, n_valid)\n",
    "y_train, y_valid, y_test = split_vals_test(y, n_trn, n_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:53:38.657084Z",
     "start_time": "2018-12-04T18:53:37.954717Z"
    }
   },
   "outputs": [],
   "source": [
    "train_cats(df)\n",
    "X_2, y_2, _ = proc_df(df, 'endprice')\n",
    "\n",
    "n_trn_2 = len(X_2) // 2\n",
    "n_valid_2 = n_trn_2 + (len(X_2) // 4)\n",
    "X_train_2, X_valid_2, X_test_2 = split_vals_test(X_2, n_trn, n_valid)\n",
    "y_train_2, y_valid_2, y_test_2 = split_vals_test(y_2, n_trn, n_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare the results of our subset with the result of the entire set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:53:41.446762Z",
     "start_time": "2018-12-04T18:53:38.659300Z"
    }
   },
   "outputs": [],
   "source": [
    "m = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:00:52.334310Z",
     "start_time": "2018-12-04T18:59:37.286174Z"
    }
   },
   "outputs": [],
   "source": [
    "m.fit(X_train_2, y_train_2)\n",
    "error_margins = fci.random_forest_error(m, X_train_2, X_test_2)\n",
    "print_score(m, X_train_2, y_train_2, X_valid_2, y_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:02:19.202932Z",
     "start_time": "2018-12-04T19:02:19.197855Z"
    }
   },
   "outputs": [],
   "source": [
    "len(error_margins)\n",
    "len(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:54:06.669427Z",
     "start_time": "2018-12-04T18:53:32.536Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function returns the r-squared, as well as the lower bound of the 95% confidence interval \n",
    "# and the upper bound of the 95% confidence interval.\n",
    "def evaluate_ols(reference_set, rel_features, comp_features):\n",
    "        data = reference_set[rel_features + comp_features + ['endprice']]\n",
    "        data = data.astype(float)\n",
    "        X = np.asarray(data[rel_features + comp_features])\n",
    "        y = np.asarray(data['endprice'])\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        r = est2.rsquared\n",
    "        lb = np.array(est2.conf_int())[:,0]\n",
    "        ub = np.array(est2.conf_int())[:,1]\n",
    "        return r, lb, ub\n",
    "    \n",
    "def predict_forest(data, target_house, model):\n",
    "    train_cats(data)\n",
    "    train_cats(target_house)\n",
    "    X, y, _ = proc_df(data, 'endprice')\n",
    "    target_house, _, _ = proc_df(target_house)\n",
    "    model.fit(X, y)\n",
    "    ans = model.predict(target_house)\n",
    "    return ans\n",
    "    \n",
    "def evaluate_model(weights, rel_feats, comp_feats, data, target_houses, thres=1):\n",
    "    m = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "    df = data.copy()\n",
    "    predictions = []\n",
    "    real_vals = []\n",
    "#     For each house in target_houses we calculate the difference between our predicted endprice and the actual endprice.\n",
    "    for i, row in target_houses.iterrows():\n",
    "        real_val = target_houses[target_houses.index.isin([i])]['endprice'].iloc[0]\n",
    "        t_house = target_houses[target_houses.index.isin([i])][rel_feats + comp_feats]\n",
    "        ref_set = get_reference_sets(weights, rel_feats, comp_feats, df, t_house, thres=1)\n",
    "        ref_set = ref_set[rel_feats + comp_feats + ['endprice']].dropna()\n",
    "#         return ref_set\n",
    "#       Calculate the predicted end price for the subset with reduced dimensions.\n",
    "        pred_endprice = predict_forest(ref_set, t_house, m)\n",
    "        predictions.append(pred_endprice[0])\n",
    "        real_vals.append(real_val)\n",
    "    return predictions, real_vals\n",
    "    \n",
    "def euclidean_distance_evaluation(model_pred, full_pred, actual_val):\n",
    "    a = np.array(model_pred)\n",
    "    b = np.array(full_pred)\n",
    "    c = np.array(actual_val)\n",
    "    d_1 = a-c\n",
    "    ans_1 = np.sqrt(d_1.dot(d_1))\n",
    "    d_2 = b-c\n",
    "    ans_2 = np.sqrt(d_2.dot(d_2))\n",
    "    return ans_1, ans_2\n",
    "\n",
    "def run_evaluation(t_houses_size, weights, rel_feats, comp_feats, data, fitted_model, thres=1):\n",
    "    t_houses = data.loc[random.sample(list(df.index), t_houses_size)]\n",
    "    ans = evaluate_model(weights, rcf, compare_features, df, t_houses)\n",
    "    m = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "    train_cats(data)\n",
    "    cols = list(set(data.columns) - set(['endprice']))\n",
    "    X_2, y_2, _ = proc_df(data, 'endprice')\n",
    "    X_2 = X_2[cols]\n",
    "    m.fit(X_2, y_2)\n",
    "    train_cats(t_houses)\n",
    "    t_houses, actual_values, _ = proc_df(t_houses, 'endprice')\n",
    "    t_houses = t_houses[cols].fillna(0)\n",
    "    fm_ans = m.predict(t_houses)\n",
    "    distances = euclidean_distance_evaluation(ans[0], fm_ans, ans[1])\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the model a (relatively large) number of times we can see how well our predictions behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:54:06.670426Z",
     "start_time": "2018-12-04T18:53:32.627Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_dists = run_evaluation(3, weights, rcf, compare_features, df, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:54:06.671466Z",
     "start_time": "2018-12-04T18:53:32.630Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:54:06.672487Z",
     "start_time": "2018-12-04T18:53:32.632Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y, _ = proc_df(t, 'endprice')\n",
    "m.fit(X, y)\n",
    "m.predict([np.array(X.iloc[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the standard regression we always use from scikit learn but it's hard to gain insights from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:54:06.673491Z",
     "start_time": "2018-12-04T18:53:32.728Z"
    }
   },
   "outputs": [],
   "source": [
    "score, importance_df = feature_importance (ref_sets, rcf, compare_features)\n",
    "print (\"Regression R2 score : \", score,'\\n\\nfeature importances : \\n',importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use another package, which has slightly lower R-squared but does give insight into the impact of all the variables. This is similar to what we see for STATA during the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:54:06.674558Z",
     "start_time": "2018-12-04T18:53:32.853Z"
    }
   },
   "outputs": [],
   "source": [
    "m = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:54:06.676279Z",
     "start_time": "2018-12-04T18:53:32.862Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[rcf + compare_features + ['endprice']].dropna()\n",
    "data = data.astype(float)\n",
    "X = np.asarray(data[rcf + compare_features])\n",
    "y = np.asarray(data['endprice'])\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
