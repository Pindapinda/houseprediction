{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.189456Z",
     "start_time": "2018-12-01T21:53:23.600030Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numbers\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tkinter import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For earlier analysis, we took the log of the endprice, this time however, we are interested in the effect of certain variables on  the real endprice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.328294Z",
     "start_time": "2018-12-01T21:53:24.190989Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pickle.load(open('houses.p','rb'))\n",
    "df['endprice'] = np.exp(df['endprice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a few comparable features, we should add some more in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.344099Z",
     "start_time": "2018-12-01T21:53:24.340070Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_features = ['bathroom.badkamer','feature.zwembad','bathroom.aparte toilet','balcony.balkon','feature.sauna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.366288Z",
     "start_time": "2018-12-01T21:53:24.345811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathroom.badkamer         0\n",
       "feature.zwembad           0\n",
       "bathroom.aparte toilet    1\n",
       "balcony.balkon            0\n",
       "feature.sauna             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[compare_features].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.466510Z",
     "start_time": "2018-12-01T21:53:24.369355Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=compare_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.471571Z",
     "start_time": "2018-12-01T21:53:24.467692Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = {\"volume\" : 0.275818,\n",
    "            \"livingspace\" : 0.251524,\n",
    "            \"Gemiddelde woningwaarde:x 1 000 euro\" : 0.113488,\n",
    "#            \"housetype\" : 0.054045,\n",
    "           \"V1.x\":0.036266,\n",
    "           \"lotsurface\":0.029131,\n",
    "           \"yearofconstruction\":0.020824,\n",
    "           \"longitude\":0.017308,\n",
    "           'latitude':0.012521}\n",
    "#            'housesubtype':0.011934}\n",
    "rcf = list(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.478861Z",
     "start_time": "2018-12-01T21:53:24.473133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78294"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.503315Z",
     "start_time": "2018-12-01T21:53:24.480324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "volume                                     49\n",
       "livingspace                              4575\n",
       "Gemiddelde woningwaarde:x 1 000 euro     1866\n",
       "V1.x                                        0\n",
       "lotsurface                              24943\n",
       "yearofconstruction                       4288\n",
       "longitude                                   0\n",
       "latitude                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[rcf].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.515338Z",
     "start_time": "2018-12-01T21:53:24.505010Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = {\"volume\" : 0.275818,\n",
    "            \"livingspace\" : 0.251524,\n",
    "            \"Gemiddelde woningwaarde:x 1 000 euro\" : 0.113488,\n",
    "#            \"housetype\" : 0.054045,\n",
    "           \"V1.x\":0.036266,\n",
    "           \"lotsurface\":0.029131,\n",
    "           \"yearofconstruction\":0.020824,\n",
    "           \"longitude\":0.017308,\n",
    "           'latitude':0.012521}\n",
    "#            'housesubtype':0.011934}\n",
    "\n",
    "#Normalize weights \n",
    "sum_vals = sum(weights.values())\n",
    "for key in weights.keys():\n",
    "    weights[key] = weights[key] / sum_vals\n",
    "    \n",
    "rcf = list(weights.keys())\n",
    "#ccf = [\"housesubtype\",\"housetype\"]\n",
    "#ccf = ['feature.zwembad','feature.sauna', 'feature.glasvezelkabel']\n",
    "#       'feature.stoomcabine', 'feature.stoomcabine','feature.jacuzzi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.549397Z",
     "start_time": "2018-12-01T21:53:24.516750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appartement        19794\n",
       "eengezinswoning     4409\n",
       "herenhuis            310\n",
       "villa                168\n",
       "bungalow             146\n",
       "woonboerderij         65\n",
       "landhuis              28\n",
       "woonboot              14\n",
       "grachtenpand           8\n",
       "stacaravan             1\n",
       "landgoed               0\n",
       "Name: housetype, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['lotsurface'].isnull()].housetype.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column with the most missing values is \"lotsurface\". Looking at how these missing values are centered, we see that most of these missing values happen for appartments (which is to be expected). As it turns out, all appartments have lotsurface Nan. For the purpose of the regression we put this value to 0 for all appartments.\n",
    "\n",
    "For all the other values, in order to empower regression, we could either drop the row or set the value to the average of the housetype. Since there appears to be plenty of data without Nans and since we want to use mostly accurate data, we decide to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.655818Z",
     "start_time": "2018-12-01T21:53:24.551965Z"
    }
   },
   "outputs": [],
   "source": [
    "df['lotsurface'] = np.where(df['housetype'] == 'appartement', 0, df['lotsurface'])\n",
    "df = df.dropna(subset=rcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.700486Z",
     "start_time": "2018-12-01T21:53:24.657212Z"
    }
   },
   "outputs": [],
   "source": [
    "# weights --> dictionary of feature name to importance\n",
    "# data --> pandas datafram of houses with all relevant features\n",
    "# rcf --> list of all relevant features \n",
    "# puf --> list of all potentially upgradable features -should be a subset of relevant features \n",
    "# thres --> maximum distance a house can have from the target house if it is to be put in a reference set \n",
    "# target_house\n",
    "\n",
    "def normalize_column(x):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return x_scaled, min_max_scaler\n",
    "\n",
    "def weightedL2(a,b,w):\n",
    "    q = a-b\n",
    "    return np.sqrt((w*q*q).sum())\n",
    "\n",
    "# rcf --> relevent comparable features rcfv--> relevant comparable feature values puf --> potential upgradable features\n",
    "def get_reference_indices(weights, data, thres, target_values):\n",
    "    reference_indices = []\n",
    "    for i, house in enumerate(data):\n",
    "        if weightedL2(target_values, house,weights) <  thres:\n",
    "            reference_indices.append(i)\n",
    "    return reference_indices\n",
    "\n",
    "def get_reference_sets(weights, rcf, ccf, data, target_house, thres=1):\n",
    "    df_ans = data.copy()\n",
    "    df = data[rcf+ccf] # We only look only at the columns that were determined to be relevant for comparison\n",
    "    t_house = target_house[rcf+ccf]\n",
    "#     for col in ccf:\n",
    "#         val = t_house[col].iloc[0]\n",
    "#         df = df[df[col]==val]\n",
    "    for col in df[rcf].columns:\n",
    "        if (df[col].dtype in [bool,float,int,np.int64]):\n",
    "            a, b = normalize_column(df[[col]].values.astype(float))\n",
    "            df[col] = a\n",
    "            t_house[col] = b.transform(t_house[[col]].values.astype(float))\n",
    "    target_values = t_house[rcf].values\n",
    "    data_array = df[rcf].values\n",
    "#     return target_values\n",
    "    weights_arr = np.array(list(weights.copy().values()))\n",
    "    reference_index = get_reference_indices(weights_arr, data_array, thres, target_values)\n",
    "    return df_ans.iloc[reference_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:24.708045Z",
     "start_time": "2018-12-01T21:53:24.702167Z"
    }
   },
   "outputs": [],
   "source": [
    "# thresh is a measure of how close a house has to be to the target house in order for it to be similar\n",
    "thresh = 1\n",
    "t_house = pd.DataFrame(df.iloc[2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:25.777304Z",
     "start_time": "2018-12-01T21:53:24.709182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/stefan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ref_sets = get_reference_sets(weights=weights, rcf = rcf, ccf = compare_features, data= df, target_house= t_house,thres=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:25.789387Z",
     "start_time": "2018-12-01T21:53:25.778764Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_importance (reference_sets, rcf, compare_features):\n",
    "    #This function will fit a simple regression in the data and return the feature importances for each upgradable feature\n",
    "    # It will also return the test R2 score\n",
    "    #drop NaN values #note we took the easy approach and dropped everything \n",
    "    df_result = reference_sets[rcf + compare_features + ['endprice']].dropna()\n",
    "    #scaling the data\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit (df_result[rcf + compare_features])\n",
    "    #creating X,y and spliting the dataset into train and test set\n",
    "#     X = scaler.transform(df_result[rcf + compare_features])\n",
    "    X = df_result[rcf + compare_features]\n",
    "    y = df_result.endprice\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    #fitting the regression\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    score = reg.score(X_test, y_test)\n",
    "    feature_imp = pd.Series(data=reg.coef_, index = rcf+compare_features)\n",
    "    return (score,feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the standard regression we always use from scikit learn but it's hard to gain insights from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:25.896384Z",
     "start_time": "2018-12-01T21:53:25.791076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression R2 score :  0.6761654464711715 \n",
      "\n",
      "feature importances : \n",
      " volume                                      69.318784\n",
      "livingspace                               1832.048245\n",
      "Gemiddelde woningwaarde:x 1 000 euro       655.444015\n",
      "V1.x                                        -0.943188\n",
      "lotsurface                                   3.714039\n",
      "yearofconstruction                         -87.390065\n",
      "longitude                                -9038.785285\n",
      "latitude                                  9634.327674\n",
      "bathroom.badkamer                        18727.837295\n",
      "feature.zwembad                         182834.873036\n",
      "bathroom.aparte toilet                    5215.037688\n",
      "balcony.balkon                           16722.373716\n",
      "feature.sauna                            21219.125828\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "score, importance_df = feature_importance (ref_sets, rcf, compare_features)\n",
    "print (\"Regression R2 score : \", score,'\\n\\nfeature importances : \\n',importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use another package, which has slightly lower R-squared but does give insight into the impact of all the variables. This is similar to what we see for STATA during the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:25.975604Z",
     "start_time": "2018-12-01T21:53:25.899601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.660\n",
      "Model:                            OLS   Adj. R-squared:                  0.660\n",
      "Method:                 Least Squares   F-statistic:                     9874.\n",
      "Date:                Sat, 01 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        22:53:25   Log-Likelihood:            -8.5760e+05\n",
      "No. Observations:               66239   AIC:                         1.715e+06\n",
      "Df Residuals:                   66225   BIC:                         1.715e+06\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -3.684e+05    4.9e+04     -7.520      0.000   -4.64e+05   -2.72e+05\n",
      "x1            77.3279      3.658     21.140      0.000      70.159      84.497\n",
      "x2          1797.1860     16.441    109.311      0.000    1764.962    1829.410\n",
      "x3           652.7504      5.116    127.587      0.000     642.723     662.778\n",
      "x4            -0.9631      0.029    -32.878      0.000      -1.021      -0.906\n",
      "x5             3.8142      0.235     16.250      0.000       3.354       4.274\n",
      "x6           -71.6195     11.094     -6.456      0.000     -93.363     -49.876\n",
      "x7         -8526.6521    931.841     -9.150      0.000   -1.04e+04   -6700.244\n",
      "x8          8863.2590    853.543     10.384      0.000    7190.315    1.05e+04\n",
      "x9          2.002e+04    756.396     26.473      0.000    1.85e+04    2.15e+04\n",
      "x10         1.577e+05   9275.675     16.998      0.000    1.39e+05    1.76e+05\n",
      "x11         4813.0373    785.879      6.124      0.000    3272.715    6353.359\n",
      "x12         1.688e+04    962.339     17.540      0.000     1.5e+04    1.88e+04\n",
      "x13         1.952e+04   8659.036      2.255      0.024    2552.737    3.65e+04\n",
      "==============================================================================\n",
      "Omnibus:                   115121.794   Durbin-Watson:                   1.952\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       1864814441.007\n",
      "Skew:                          11.168   Prob(JB):                         0.00\n",
      "Kurtosis:                     824.687   Cond. No.                     6.25e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.25e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "data = ref_sets[rcf + compare_features + ['endprice']].dropna()\n",
    "data = data.astype(float)\n",
    "X = np.asarray(data[rcf + compare_features])\n",
    "y = np.asarray(data['endprice'])\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:53:26.044428Z",
     "start_time": "2018-12-01T21:53:25.977047Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function returns the r-squared, as well as the lower bound of the 95% confidence interval \n",
    "# and the upper bound of the 95% confidence interval.\n",
    "def evaluate_ols(reference_set, rel_features, comp_features):\n",
    "        data = reference_set[rel_features + comp_features + ['endprice']]\n",
    "        data = data.astype(float)\n",
    "        X = np.asarray(data[rel_features + comp_features])\n",
    "        y = np.asarray(data['endprice'])\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        r = est2.rsquared\n",
    "        lb = np.array(est2.conf_int())[:,0]\n",
    "        ub = np.array(est2.conf_int())[:,1]\n",
    "        return r, lb, ub\n",
    "    \n",
    "def evaluate_model(weights, rel_feats, comp_feats, data, target_houses, thres=1):\n",
    "    df = data.copy()\n",
    "    r_squareds = 0\n",
    "    lbs = np.zeros(len(rel_feats + comp_feats + ['endprice']))\n",
    "    ubs = np.zeros(len(rel_feats + comp_feats + ['endprice']))\n",
    "    for i, row in target_houses.iterrows():\n",
    "        t_house = target_houses[target_houses.index.isin([i])]\n",
    "        ref_set = get_reference_sets(weights, rel_feats, comp_feats, df, t_house, thres=1)\n",
    "        r, lb, ub = evaluate_ols(ref_set, rel_feats, comp_feats)\n",
    "        r_squareds += r\n",
    "        lbs += lb\n",
    "        ubs += ub\n",
    "    r_avg = r_squareds/len(target_houses)\n",
    "    lb_avg = lbs/len(target_houses)\n",
    "    ub_avg = ubs/len(target_houses)\n",
    "    return r_avg, lb_avg, ub_avg\n",
    "\n",
    "def run_evaluation(t_houses_size, weights, rel_feats, comp_feats, data, thres=1):\n",
    "    t_houses = df.loc[random.sample(list(df.index), t_houses_size)]\n",
    "    ans = evaluate_model(weights, rcf, compare_features, df, t_houses)\n",
    "    print(\"Average r-squared for {} inputs is: {}\".format(t_houses_size, ans[0]))\n",
    "    for i, col in enumerate(rel_feats + comp_feats + ['endprice']):\n",
    "        print(\"The column {} has an average 95% confidence interval between {} and {}\".format(col, ans[1][i], ans[2][i]))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the model a (relatively large) number of times we can see how well our predictions behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T21:57:21.526214Z",
     "start_time": "2018-12-01T21:55:42.136633Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/stefan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average r-squared for 100 inputs is: 0.6596574939811649\n",
      "The column volume has an average 95% confidence interval between -464405.25558135915 and -272371.287924488\n",
      "\n",
      "\n",
      "The column livingspace has an average 95% confidence interval between 70.1585227986871 and 84.49727582820016\n",
      "\n",
      "\n",
      "The column Gemiddelde woningwaarde:x 1 000 euro has an average 95% confidence interval between 1764.9615442611396 and 1829.410448235439\n",
      "\n",
      "\n",
      "The column V1.x has an average 95% confidence interval between 642.722850780081 and 662.7780143291016\n",
      "\n",
      "\n",
      "The column lotsurface has an average 95% confidence interval between -1.0205354211034416 and -0.9057047854534556\n",
      "\n",
      "\n",
      "The column yearofconstruction has an average 95% confidence interval between 3.3541411815716464 and 4.274251091949552\n",
      "\n",
      "\n",
      "The column longitude has an average 95% confidence interval between -93.36301956000638 and -49.875979199976335\n",
      "\n",
      "\n",
      "The column latitude has an average 95% confidence interval between -10353.060425581614 and -6700.2437350273485\n",
      "\n",
      "\n",
      "The column bathroom.badkamer has an average 95% confidence interval between 7190.315372438986 and 10536.202661048512\n",
      "\n",
      "\n",
      "The column feature.zwembad has an average 95% confidence interval between 18541.371123351626 and 21506.44257555116\n",
      "\n",
      "\n",
      "The column bathroom.aparte toilet has an average 95% confidence interval between 139489.11561235416 and 175849.75708708708\n",
      "\n",
      "\n",
      "The column balcony.balkon has an average 95% confidence interval between 3272.7153640355914 and 6353.359223581024\n",
      "\n",
      "\n",
      "The column feature.sauna has an average 95% confidence interval between 14992.94842104024 and 18765.316589816877\n",
      "\n",
      "\n",
      "The column endprice has an average 95% confidence interval between 2552.736985851252 and 36496.15603428088\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_evaluation(100, weights, rcf, compare_features, df)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
