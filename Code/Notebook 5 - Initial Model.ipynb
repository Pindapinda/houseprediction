{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T09:50:12.312796Z",
     "start_time": "2018-12-04T09:50:11.481813Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from preprocessing import *\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T09:50:12.497220Z",
     "start_time": "2018-12-04T09:50:12.328194Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pickle.load(open('X.p','rb'))\n",
    "y = pickle.load(open('y.p','rb'))\n",
    "nas = pickle.load(open('nas.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T09:50:15.624885Z",
     "start_time": "2018-12-04T09:50:15.616775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.46458334, 12.54966235, 12.20557252, ..., 12.89921983,\n",
       "       12.56024446, 12.64109656])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train, Val, and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:40:41.830292Z",
     "start_time": "2018-11-21T12:40:41.735437Z"
    }
   },
   "outputs": [],
   "source": [
    "# We use the first half of the dataset for training, the next 25% for validation and the final 25% for testing\n",
    "\n",
    "n_trn = len(X) // 2\n",
    "n_valid = n_trn + (len(X) // 4)\n",
    "X_train, X_valid, X_test = split_vals_test(X, n_trn, n_valid)\n",
    "y_train, y_valid, y_test = split_vals_test(y, n_trn, n_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:40:56.709435Z",
     "start_time": "2018-11-21T12:40:46.647991Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.4 s, sys: 170 ms, total: 39.5 s\n",
      "Wall time: 7.93 s\n",
      "[0.07975016230858385, 0.20360450275845207, 0.972181703926252, 0.8275231910300023, -6.274355518398083]\n"
     ]
    }
   ],
   "source": [
    "m = RFR(n_jobs=-1, oob_score=True)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**:  r^2 of 0.83.  Negative oob score indicates that we are not using enough estimators (decision trees) in our forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Fine-Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:43:13.718492Z",
     "start_time": "2018-11-21T12:41:22.332332Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.8 s, sys: 228 ms, total: 39 s\n",
      "Wall time: 7.71 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 1.34 s, total: 1min 20s\n",
      "Wall time: 13.2 s\n",
      "CPU times: user 3min 15s, sys: 577 ms, total: 3min 16s\n",
      "Wall time: 27.8 s\n",
      "CPU times: user 6min 28s, sys: 535 ms, total: 6min 29s\n",
      "Wall time: 52.5 s\n",
      "[0.07975358104638124, 0.20478750681643823, 0.9721793188402297, 0.825513082888144, -6.265388928154166]\n",
      "[0.07219963204187674, 0.19739455245250206, 0.9771998689981941, 0.8378838511326102, 0.7870207864999709]\n",
      "[0.06791759552642464, 0.19431219684431486, 0.9798241435914183, 0.8429072741144209, 0.8564221401928943]\n",
      "[0.06564020962977164, 0.19256999668239622, 0.9811545161374319, 0.8457116275241453, 0.8632949473340099]\n"
     ]
    }
   ],
   "source": [
    "# n_estimators\n",
    "\n",
    "m1 = RFR(n_estimators=10, n_jobs=-1, oob_score=True)\n",
    "m2 = RFR(n_estimators=20, n_jobs=-1, oob_score=True)\n",
    "m3 = RFR(n_estimators=40, n_jobs=-1, oob_score=True)\n",
    "m4 = RFR(n_estimators=80, n_jobs=-1, oob_score=True)\n",
    "%time m1.fit(X_train, y_train)\n",
    "%time m2.fit(X_train, y_train)\n",
    "%time m3.fit(X_train, y_train)\n",
    "%time m4.fit(X_train, y_train)\n",
    "print_score(m1, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m2, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m3, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m4, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** The returns on adding estimators are reduced significantly (judging from oob) when going from 40 to 80.  Thus, we'll stick with 40 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:44:48.604612Z",
     "start_time": "2018-11-21T12:43:13.949608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 196 ms, total: 2min 44s\n",
      "Wall time: 23.5 s\n",
      "CPU times: user 2min 35s, sys: 187 ms, total: 2min 35s\n",
      "Wall time: 23.2 s\n",
      "CPU times: user 2min 16s, sys: 169 ms, total: 2min 16s\n",
      "Wall time: 19.4 s\n",
      "CPU times: user 2min 5s, sys: 183 ms, total: 2min 5s\n",
      "Wall time: 18.6 s\n",
      "[0.0851868599293174, 0.19382815918790186, 0.9682595855036173, 0.8436889449371754, 0.8573316389709049]\n",
      "[0.10270202032333724, 0.1949022560433158, 0.9538655499611275, 0.8419517525424696, 0.8564470287231085]\n",
      "[0.1312313732359156, 0.19902351779966898, 0.9246743790188436, 0.835197138354816, 0.8509094078141303]\n",
      "[0.16477800055065653, 0.2074100426056273, 0.8812411916037944, 0.8210154626636681, 0.837005371786386]\n"
     ]
    }
   ],
   "source": [
    "# min_samples_leaf\n",
    "m1 = RFR(n_estimators=40, min_samples_leaf=3, n_jobs=-1, oob_score=True)\n",
    "m2 = RFR(n_estimators=40, min_samples_leaf=5, n_jobs=-1, oob_score=True)\n",
    "m3 = RFR(n_estimators=40, min_samples_leaf=10, n_jobs=-1, oob_score=True)\n",
    "m4 = RFR(n_estimators=40, min_samples_leaf=25, n_jobs=-1, oob_score=True)\n",
    "%time m1.fit(X_train, y_train)\n",
    "%time m2.fit(X_train, y_train)\n",
    "%time m3.fit(X_train, y_train)\n",
    "%time m4.fit(X_train, y_train)\n",
    "print_score(m1, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m2, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m3, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m4, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** Going from 1 to 3 (1 was the default value from the previous cell) we see the oob and validation r^2 improving slightly, so we'll go with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:45:27.056974Z",
     "start_time": "2018-11-21T12:44:49.030582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 s, sys: 111 ms, total: 2.82 s\n",
      "Wall time: 1.62 s\n",
      "CPU times: user 1min 50s, sys: 222 ms, total: 1min 50s\n",
      "Wall time: 16.6 s\n",
      "CPU times: user 16.6 s, sys: 149 ms, total: 16.7 s\n",
      "Wall time: 3.76 s\n",
      "CPU times: user 10.2 s, sys: 165 ms, total: 10.4 s\n",
      "Wall time: 3.17 s\n",
      "[0.3127580206869916, 0.3548328579380348, 0.5721571428331118, 0.4761540260934751, 0.4932793707139609]\n",
      "[0.0866491451808251, 0.19280843133471592, 0.9671605451439951, 0.8453293201053674, 0.8601555772093379]\n",
      "[0.11005641846554352, 0.2092943441313079, 0.9470216869801372, 0.8177485733206248, 0.8367962656639258]\n",
      "[0.13489458498261578, 0.23266414648865857, 0.9204103845252798, 0.7747758899726638, 0.7945185126551586]\n"
     ]
    }
   ],
   "source": [
    "# max_feaures\n",
    "\n",
    "m1 = RFR(n_estimators=40, min_samples_leaf=3, max_features=1, n_jobs=-1, oob_score=True)\n",
    "m2 = RFR(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m3 = RFR(n_estimators=40, min_samples_leaf=3, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "m4 = RFR(n_estimators=40, min_samples_leaf=3, max_features='log2', n_jobs=-1, oob_score=True)\n",
    "%time m1.fit(X_train, y_train)\n",
    "%time m2.fit(X_train, y_train)\n",
    "%time m3.fit(X_train, y_train)\n",
    "%time m4.fit(X_train, y_train)\n",
    "print_score(m1, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m2, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m3, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m4, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** max_features = 0.5 is the clear winner here.  I'll now re-train the forest with more estimators to see if that yields any additional gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:48:00.615463Z",
     "start_time": "2018-11-21T12:45:27.435900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 246 ms, total: 1min 56s\n",
      "Wall time: 20.6 s\n",
      "CPU times: user 2min 56s, sys: 351 ms, total: 2min 56s\n",
      "Wall time: 30.2 s\n",
      "CPU times: user 3min 57s, sys: 555 ms, total: 3min 57s\n",
      "Wall time: 40.6 s\n",
      "CPU times: user 4min 50s, sys: 826 ms, total: 4min 51s\n",
      "Wall time: 48.8 s\n",
      "[0.08685545606794018, 0.19321837672180223, 0.9670039780406083, 0.8446709055521905, 0.8604889946618992]\n",
      "[0.08572343459389575, 0.19283930382215253, 0.9678584734072976, 0.8452797843990623, 0.8650044744559671]\n",
      "[0.08531824533294104, 0.19182696862235832, 0.9681616022445615, 0.8468999686226957, 0.8664799947262254]\n",
      "[0.0849487953752823, 0.19128687586703105, 0.9684367421494987, 0.8477608675171076, 0.8678186755535187]\n"
     ]
    }
   ],
   "source": [
    "# max_feaures\n",
    "\n",
    "m1 = RFR(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m2 = RFR(n_estimators=60, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m3 = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m4 = RFR(n_estimators=100, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "%time m1.fit(X_train, y_train)\n",
    "%time m2.fit(X_train, y_train)\n",
    "%time m3.fit(X_train, y_train)\n",
    "%time m4.fit(X_train, y_train)\n",
    "print_score(m1, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m2, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m3, X_train, y_train, X_valid, y_valid)\n",
    "print_score(m4, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** we see some minor improvement going from 40 to 80, but above that the changes are really negligible.  We'll stick with 80 as our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:48:01.097440Z",
     "start_time": "2018-11-21T12:48:00.970921Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = m3\n",
    "pickle.dump(best_model, open('nb5_best.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:48:01.500940Z",
     "start_time": "2018-11-21T12:48:01.424235Z"
    }
   },
   "outputs": [],
   "source": [
    "best = pickle.load(open('nb5_best.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T12:48:01.982134Z",
     "start_time": "2018-11-21T12:48:01.852587Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump([X_train, y_train], open('train.p','wb'))\n",
    "pickle.dump([X_valid, y_valid], open('valid.p','wb'))\n",
    "pickle.dump([X_test, y_test], open('test.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
