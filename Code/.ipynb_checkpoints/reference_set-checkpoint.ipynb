{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.110733Z",
     "start_time": "2018-12-04T11:04:45.434360Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numbers\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tkinter import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from preprocessing import *\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from preprocessing import *\n",
    "\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For earlier analysis, we took the log of the endprice, this time however, we are interested in the effect of certain variables on  the real endprice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.217681Z",
     "start_time": "2018-12-04T11:04:46.112191Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pickle.load(open('houses.p','rb'))\n",
    "train_cats(df)\n",
    "# df['endprice'] = np.exp(df['endprice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a few comparable features, we should add some more in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.221505Z",
     "start_time": "2018-12-04T11:04:46.219179Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_features = ['bathroom.badkamer','feature.zwembad','bathroom.aparte toilet','balcony.balkon','feature.sauna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.239597Z",
     "start_time": "2018-12-04T11:04:46.223282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathroom.badkamer         0\n",
       "feature.zwembad           0\n",
       "bathroom.aparte toilet    1\n",
       "balcony.balkon            0\n",
       "feature.sauna             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[compare_features].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.317957Z",
     "start_time": "2018-12-04T11:04:46.241558Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=compare_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.324542Z",
     "start_time": "2018-12-04T11:04:46.319674Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = {\"livingspace\" : 0.377048,\n",
    "           \"Gemiddelde woningwaarde:x 1 000 euro\" : 0.148191,\n",
    "           \"housetype\" : 0.116821,\n",
    "           \"V1.x\":0.031711,\n",
    "           \"lotsurface\":0.045889,\n",
    "           \"yearofconstruction\":0.024880,\n",
    "           \"longitude\":0.016243,\n",
    "           'latitude':0.013181,\n",
    "           'housesubtype':0.018080,\n",
    "           'rooms' : 0.016288\n",
    "        }\n",
    "rcf = list(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.332120Z",
     "start_time": "2018-12-04T11:04:46.326668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78294"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.358506Z",
     "start_time": "2018-12-04T11:04:46.333576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "livingspace                              4575\n",
       "Gemiddelde woningwaarde:x 1 000 euro     1866\n",
       "housetype                                   0\n",
       "V1.x                                        0\n",
       "lotsurface                              24943\n",
       "yearofconstruction                       4288\n",
       "longitude                                   0\n",
       "latitude                                    0\n",
       "housesubtype                                0\n",
       "rooms                                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[rcf].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.375351Z",
     "start_time": "2018-12-04T11:04:46.360619Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = {\"livingspace\" : 0.377048,\n",
    "           \"Gemiddelde woningwaarde:x 1 000 euro\" : 0.148191,\n",
    "           \"housetype\" : 0.116821,\n",
    "           \"V1.x\":0.031711,\n",
    "           \"lotsurface\":0.045889,\n",
    "           \"yearofconstruction\":0.024880,\n",
    "           \"longitude\":0.016243,\n",
    "           'latitude':0.013181,\n",
    "           'housesubtype':0.018080,\n",
    "           'rooms' : 0.016288\n",
    "        }\n",
    "\n",
    "#Normalize weights \n",
    "sum_vals = sum(weights.values())\n",
    "for key in weights.keys():\n",
    "    weights[key] = weights[key] / sum_vals\n",
    "    \n",
    "rcf = list(weights.keys())\n",
    "#ccf = [\"housesubtype\",\"housetype\"]\n",
    "#ccf = ['feature.zwembad','feature.sauna', 'feature.glasvezelkabel']\n",
    "#       'feature.stoomcabine', 'feature.stoomcabine','feature.jacuzzi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.403932Z",
     "start_time": "2018-12-04T11:04:46.377391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appartement        19794\n",
       "eengezinswoning     4409\n",
       "herenhuis            310\n",
       "villa                168\n",
       "bungalow             146\n",
       "woonboerderij         65\n",
       "landhuis              28\n",
       "woonboot              14\n",
       "grachtenpand           8\n",
       "stacaravan             1\n",
       "landgoed               0\n",
       "Name: housetype, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['lotsurface'].isnull()].housetype.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column with the most missing values is \"lotsurface\". Looking at how these missing values are centered, we see that most of these missing values happen for appartments (which is to be expected). As it turns out, all appartments have lotsurface Nan. For the purpose of the regression we put this value to 0 for all appartments.\n",
    "\n",
    "For all the other values, in order to empower regression, we could either drop the row or set the value to the average of the housetype. Since there appears to be plenty of data without Nans and since we want to use mostly accurate data, we decide to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.491459Z",
     "start_time": "2018-12-04T11:04:46.405324Z"
    }
   },
   "outputs": [],
   "source": [
    "df['lotsurface'] = np.where(df['housetype'] == 'appartement', 0, df['lotsurface'])\n",
    "df = df.dropna(subset=rcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still left with 66239 rows, which should be plenty of data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.548888Z",
     "start_time": "2018-12-04T11:04:46.493088Z"
    }
   },
   "outputs": [],
   "source": [
    "# weights --> dictionary of feature name to importance\n",
    "# data --> pandas datafram of houses with all relevant features\n",
    "# rcf --> list of all relevant features \n",
    "# puf --> list of all potentially upgradable features -should be a subset of relevant features \n",
    "# thres --> maximum distance a house can have from the target house if it is to be put in a reference set \n",
    "# target_house\n",
    "\n",
    "def normalize_column(x):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return x_scaled, min_max_scaler\n",
    "\n",
    "def weightedL2(a,b,w):\n",
    "    dif = []\n",
    "    for i, val in enumerate(a[0]):\n",
    "        if(type(val)==type(\"a\")):\n",
    "            if val == b[i]:\n",
    "                dif.append(0)\n",
    "            else:\n",
    "                dif.append(1)\n",
    "        else:\n",
    "            dif.append(abs(a[0][i]-b[i]))\n",
    "    q = dif\n",
    "    return np.sqrt((w*q*q).sum())\n",
    "\n",
    "# rcf --> relevent comparable features rcfv--> relevant comparable feature values puf --> potential upgradable features\n",
    "def get_reference_indices(weights, data, thres, target_values):\n",
    "    reference_indices = []\n",
    "    for i, house in enumerate(data):\n",
    "        if weightedL2(target_values, house,weights) <  thres:\n",
    "            reference_indices.append(i)\n",
    "    return reference_indices\n",
    "\n",
    "def get_reference_sets(weights, rcf, ccf, data, target_house, thres=1):\n",
    "    df_ans = data.copy()\n",
    "    df = data[rcf+ccf] # We only look only at the columns that were determined to be relevant for comparison\n",
    "    t_house = target_house[rcf+ccf]\n",
    "#     for col in ccf:\n",
    "#         val = t_house[col].iloc[0]\n",
    "#         df = df[df[col]==val]\n",
    "    for col in df[rcf].columns:\n",
    "        if (df[col].dtype in [bool,float,int,np.int64]):\n",
    "            a, b = normalize_column(df[[col]].values.astype(float))\n",
    "            df[col] = a\n",
    "            t_house[col] = b.transform(t_house[[col]].values.astype(float))\n",
    "    target_values = t_house[rcf].values\n",
    "    data_array = df[rcf].values\n",
    "#     return target_values\n",
    "    weights_arr = np.array(list(weights.copy().values()))\n",
    "    reference_index = get_reference_indices(weights_arr, data_array, thres, target_values)\n",
    "    return df_ans.iloc[reference_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:46.559727Z",
     "start_time": "2018-12-04T11:04:46.550661Z"
    }
   },
   "outputs": [],
   "source": [
    "# thresh is a measure of how close a house has to be to the target house in order for it to be similar\n",
    "thresh = 1\n",
    "t_house = pd.DataFrame(df.iloc[2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:48.322078Z",
     "start_time": "2018-12-04T11:04:46.561319Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/stefan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ref_sets = get_reference_sets(weights=weights, rcf = rcf, ccf = compare_features, data= df, target_house= t_house,thres=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:48.334909Z",
     "start_time": "2018-12-04T11:04:48.323486Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_importance (reference_sets, rcf, compare_features):\n",
    "    #This function will fit a simple regression in the data and return the feature importances for each upgradable feature\n",
    "    # It will also return the test R2 score\n",
    "    #drop NaN values #note we took the easy approach and dropped everything \n",
    "    df_result = reference_sets[rcf + compare_features + ['endprice']].dropna()\n",
    "    #scaling the data\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit (df_result[rcf + compare_features])\n",
    "    #creating X,y and spliting the dataset into train and test set\n",
    "#     X = scaler.transform(df_result[rcf + compare_features])\n",
    "    X = df_result[rcf + compare_features]\n",
    "    y = df_result.endprice\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    #fitting the regression\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    score = reg.score(X_test, y_test)\n",
    "    feature_imp = pd.Series(data=reg.coef_, index = rcf+compare_features)\n",
    "    return (score,feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we're gonna try to do this based on the randomforrestregression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string data to categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:48.467640Z",
     "start_time": "2018-12-04T11:04:48.337373Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = ref_sets[rcf + compare_features + ['endprice']].dropna()\n",
    "train_cats(data)\n",
    "X, y, _ = proc_df(data, 'endprice')\n",
    "\n",
    "n_trn = len(X) // 2\n",
    "n_valid = n_trn + (len(X) // 4)\n",
    "X_train, X_valid, X_test = split_vals_test(X, n_trn, n_valid)\n",
    "y_train, y_valid, y_test = split_vals_test(y, n_trn, n_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:49.021495Z",
     "start_time": "2018-12-04T11:04:48.469384Z"
    }
   },
   "outputs": [],
   "source": [
    "train_cats(df)\n",
    "X_2, y_2, _ = proc_df(df, 'endprice')\n",
    "\n",
    "n_trn_2 = len(X_2) // 2\n",
    "n_valid_2 = n_trn_2 + (len(X_2) // 4)\n",
    "X_train_2, X_valid_2, X_test_2 = split_vals_test(X_2, n_trn, n_valid)\n",
    "y_train_2, y_valid_2, y_test_2 = split_vals_test(y_2, n_trn, n_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare the results of our subset with the result of the entire set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:04:51.657328Z",
     "start_time": "2018-12-04T11:04:49.022893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10286454749501117, 0.19126907274980504, 0.9523767282495353, 0.8441404716783527, 0.8632554649866215]\n"
     ]
    }
   ],
   "source": [
    "m = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:05:14.867677Z",
     "start_time": "2018-12-04T11:04:51.659167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08210105246231066, 0.18597664358257895, 0.9696621194278456, 0.8526464294814394, 0.8713394965170425]\n"
     ]
    }
   ],
   "source": [
    "m.fit(X_train_2, y_train_2)\n",
    "print_score(m, X_train_2, y_train_2, X_valid_2, y_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:05:59.821192Z",
     "start_time": "2018-12-04T11:05:59.746525Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function returns the r-squared, as well as the lower bound of the 95% confidence interval \n",
    "# and the upper bound of the 95% confidence interval.\n",
    "def evaluate_ols(reference_set, rel_features, comp_features):\n",
    "        data = reference_set[rel_features + comp_features + ['endprice']]\n",
    "        data = data.astype(float)\n",
    "        X = np.asarray(data[rel_features + comp_features])\n",
    "        y = np.asarray(data['endprice'])\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        r = est2.rsquared\n",
    "        lb = np.array(est2.conf_int())[:,0]\n",
    "        ub = np.array(est2.conf_int())[:,1]\n",
    "        return r, lb, ub\n",
    "    \n",
    "def predict_forest(data, target_house, model):\n",
    "    t = train_cats_func(data)\n",
    "    X, y, _ = proc_df(t, 'endprice')\n",
    "    model.fit(X, y)\n",
    "    ans = model.predict(target_house)\n",
    "    print(ans)\n",
    "    return ans - target_house['endprice'].iloc[0]\n",
    "    \n",
    "def evaluate_model(weights, rel_feats, comp_feats, data, target_houses, thres=1):\n",
    "    m = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "    df = data.copy()\n",
    "    error_sum = 0\n",
    "#     For each house in target_houses we calculate the difference between our predicted endprice and the actual endprice.\n",
    "    for i, row in target_houses.iterrows():\n",
    "        t_house = target_houses[target_houses.index.isin([i])]\n",
    "        ref_set = get_reference_sets(weights, rel_feats, comp_feats, df, t_house, thres=1)\n",
    "        ref_set = ref_set[rel_feats + comp_feats + ['endprice']]\n",
    "#         return ref_set\n",
    "#       Calculate the predicted end price for the subset with reduced dimensions.\n",
    "        pred_endprice = predict_forest(ref_set, t_house, m)\n",
    "    return error_sum, \"hi\", \"bi\"\n",
    "\n",
    "def run_evaluation(t_houses_size, weights, rel_feats, comp_feats, data, thres=1):\n",
    "    t_houses = data.loc[random.sample(list(df.index), t_houses_size)]\n",
    "    ans = evaluate_model(weights, rcf, compare_features, df, t_houses)\n",
    "    print(\"Average r-squared for {} inputs is: {}\".format(t_houses_size, ans[0]))\n",
    "    for i, col in enumerate(rel_feats + comp_feats + ['endprice']):\n",
    "        print(\"The column {} has an average 95% confidence interval between {} and {}\".format(col, ans[1][i], ans[2][i]))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the model a (relatively large) number of times we can see how well our predictions behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:06:15.506455Z",
     "start_time": "2018-12-04T11:06:09.785361Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/stefan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'WD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a0d907e63513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-601c17604cec>\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(t_houses_size, weights, rel_feats, comp_feats, data, thres)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_houses_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mt_houses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_houses_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_houses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average r-squared for {} inputs is: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_houses_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_feats\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcomp_feats\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'endprice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-601c17604cec>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(weights, rel_feats, comp_feats, data, target_houses, thres)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#         return ref_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#       Calculate the predicted end price for the subset with reduced dimensions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mpred_endprice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_house\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bi\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-601c17604cec>\u001b[0m in \u001b[0;36mpredict_forest\u001b[0;34m(data, target_house, model)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'endprice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_house\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget_house\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'endprice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    375\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'WD'"
     ]
    }
   ],
   "source": [
    "run_evaluation(100, weights, rcf, compare_features, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:05:21.465512Z",
     "start_time": "2018-12-04T11:05:16.851903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.47862987])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, _ = proc_df(t, 'endprice')\n",
    "m.fit(X, y)\n",
    "m.predict([np.array(X.iloc[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the standard regression we always use from scikit learn but it's hard to gain insights from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:05:21.737947Z",
     "start_time": "2018-12-04T11:05:21.471045Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2-onder-1-kapwoning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e95090f09e7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_importance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Regression R2 score : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n\\nfeature importances : \\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimportance_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a5672d4568de>\u001b[0m in \u001b[0;36mfeature_importance\u001b[0;34m(reference_sets, rcf, compare_features)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#fitting the regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfeature_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcompare_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 482\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2-onder-1-kapwoning'"
     ]
    }
   ],
   "source": [
    "score, importance_df = feature_importance (ref_sets, rcf, compare_features)\n",
    "print (\"Regression R2 score : \", score,'\\n\\nfeature importances : \\n',importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use another package, which has slightly lower R-squared but does give insight into the impact of all the variables. This is similar to what we see for STATA during the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:05:21.739048Z",
     "start_time": "2018-12-04T11:04:47.430Z"
    }
   },
   "outputs": [],
   "source": [
    "m = RFR(n_estimators=80, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T11:05:21.740244Z",
     "start_time": "2018-12-04T11:04:47.433Z"
    }
   },
   "outputs": [],
   "source": [
    "data = ref_sets[rcf + compare_features + ['endprice']].dropna()\n",
    "data = data.astype(float)\n",
    "X = np.asarray(data[rcf + compare_features])\n",
    "y = np.asarray(data['endprice'])\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
